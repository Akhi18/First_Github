{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbourhood Segmentation and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to segment, and cluster the neighborhoods in the city of Toronto.\n",
    "\n",
    "For the Toronto neighborhood data, a Wikipedia page exists that has all the information we need to explore and cluster the neighborhoods in Toronto. As data is not readily available, we are going to scrape the Wikipedia page and wrangle the data, clean it using the utility **BeautifulSoup** and then read it into a pandas dataframe so that it is in a structured format.\n",
    "\n",
    "Once the data is in a structured format, we can explore and cluster the neighborhoods in the city of Toronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/lib/python3.6/site-packages (4.6.3)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/lib/python3.6/site-packages (2.20.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (2.7)\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import pip\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **Beautiful Soup** is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping. It is available for Python 2.7 and Python 3. First, we are going to import the wikipedia page source code and parse it using the BeautifulSoup package. Next, we extract the table containing the required postcodes and other details and load each row of data into a **.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the wikipedia page & parsing\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the necessary table details from soup\n",
    "table = soup.findAll('table', class_ = 'wikitable sortable')\n",
    "len(table)\n",
    "table = table[0] #checking for multiple tables and choosing the correct one\n",
    "type(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8804"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the table data, formatting & loading to a .csv file\n",
    "import csv\n",
    "import os\n",
    "\n",
    "table_data = table_data_new=\"\"\n",
    "for row in table.findAll('tr'):\n",
    "    table_data = \"\"\n",
    "    for cell in row.findAll('td'):\n",
    "        table_data = table_data+\"|\"+cell.text\n",
    "    for cell in row.findAll('th'):\n",
    "        table_data = table_data+\"|\"+cell.text\n",
    "    if len(table_data)!=0:\n",
    "        table_data_new = table_data_new+table_data[1:]\n",
    "    \n",
    "file=open(os.path.expanduser(\"postal_codes.csv\"), \"wb\") \n",
    "file.write(bytes(table_data_new, encoding = \"ascii\", errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1A</td>\n",
       "      <td>Not assigned</td>\n",
       "      <td>Not assigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2A</td>\n",
       "      <td>Not assigned</td>\n",
       "      <td>Not assigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M3A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Parkwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M4A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Victoria Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M5A</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Harbourfront</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode           Borough     Neighbourhood\n",
       "0      M1A      Not assigned      Not assigned\n",
       "1      M2A      Not assigned      Not assigned\n",
       "2      M3A        North York         Parkwoods\n",
       "3      M4A        North York  Victoria Village\n",
       "4      M5A  Downtown Toronto      Harbourfront"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing .csv file to a dataframe using Python\n",
    "df = pd.read_csv('postal_codes.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataframe consists of three columns: PostalCode, Borough, and Neighborhood. We need to process the cells that have an assigned borough and ignore cells with a borough that is Not assigned. More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, we notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma.\n",
    "\n",
    "If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. For example, for the postal code M7A, the value of the Borough and the Neighborhood columns will be Queen's Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleansing data \n",
    "df = df.drop(df[df['Borough']=='Not assigned'].index)\n",
    "\n",
    "import numpy as py\n",
    "df['Neighbourhood'] = py.where(df['Neighbourhood'] == 'Not assigned', df['Borough'], df['Neighbourhood'])\n",
    "df = df.groupby('Postcode').agg({'Borough':'first', \n",
    "                             'Neighbourhood': ', '.join, \n",
    "                             'Borough':'first' }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the cleaned data in the .csv file\n",
    "df.to_csv(\"postal_codes.csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for number of rows in final dataframe\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
